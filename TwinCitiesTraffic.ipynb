{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "Dependencies\n",
    "##############\n",
    "\n",
    "import pandas as pd                              ### import pandas ###\n",
    "import os                                        ### import operating system ###\n",
    "import xml.etree.ElementTree as ET               ### xml.etree is a flexible container object,\n",
    "                                                 #   designed to store hierarchical data structures in memory.###\n",
    "import gzip                                      ### compress and decompress gzip files ###\n",
    "import time                                      ### import time libraries ###\n",
    "import shutil                                    ### Higher level copying and archiving ###\n",
    "import requests                                  ### Libraries to support HTML requests in python ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Defenition to pull Incident Reports and Traffic Detectors from MN DOT\n",
    "####################################################################\n",
    "# Request incident information - xml.gz file\n",
    "# Open, decompress, and decode\n",
    "# Request traffic detector information - xml.gz file\n",
    "# Open, decompress, and decode\n",
    "\n",
    "def download():\n",
    "    i = requests.get('http://data.dot.state.mn.us/iris_xml/incident.xml.gz')\n",
    "    with open('incidents.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(i.content).decode('utf-8'))\n",
    "    d = requests.get('http://data.dot.state.mn.us/iris_xml/det_sample.xml.gz')\n",
    "    with open('det_sample.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(d.content).decode('ISO-8859-1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Defenition to convert information in DataFrames\n",
    "###################################################\n",
    "# Identify crash information, try to open csv file and convert to DF, save updated DF as csv\n",
    "# Identify detector information, try to open as csv and convert to DF, save updated DF as csv\n",
    "\n",
    "\n",
    "def data_check():\n",
    "        XMLfile = \"incident.xml\"\n",
    "        try:\n",
    "            with open('crash_data.csv', 'r') as CD:\n",
    "                incidents()\n",
    "        except FileNotFoundError:\n",
    "                All_Crash_Data = pd.DataFrame(columns=['Name', 'Date', 'Direction', 'Road', 'Location', 'Event'])\n",
    "                with open('crash_data.csv', 'w') as f:\n",
    "                    All_Crash_Data.to_csv(f, header=True)\n",
    "                    incidents()\n",
    "        XMLfile = \"det_sample.xml\"\n",
    "        try:\n",
    "            with open('detector_data.csv', 'r') as CD:\n",
    "                detectors()\n",
    "        except FileNotFoundError:\n",
    "                Detector_Data = pd.DataFrame(columns=['Sensor', 'Time', 'Occupancy', 'Speed', 'Flow'])\n",
    "                with open('detector_data.csv', 'w') as f:\n",
    "                    Detector_Data.to_csv(f, header=True)\n",
    "                    detectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse incident information and save into csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "\n",
    "def incidents():\n",
    "        XMLfile = \"incidents.xml\"\n",
    "\n",
    "\n",
    "        dates = []\n",
    "        incident_dirs = []\n",
    "        roads = []\n",
    "        locations = []\n",
    "        names = []\n",
    "        events = []\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                dates.append(child.attrib['event_date'])\n",
    "            except KeyError:\n",
    "                dates.append(\"NA\")\n",
    "            try:\n",
    "                names.append(str(child.attrib['name']))\n",
    "            except KeyError:\n",
    "                name.append(\"NA\")\n",
    "            try:\n",
    "                incident_dirs.append(child.attrib['dir'])\n",
    "            except KeyError:\n",
    "                incident_dir.append(\"NA\")\n",
    "            try:\n",
    "                roads.append(child.attrib['road'])\n",
    "            except KeyError:\n",
    "                roads.append('NA')\n",
    "            try:\n",
    "                locations.append(child.attrib['location'])\n",
    "            except KeyError:\n",
    "                locations.append(\"NA\")\n",
    "            try: \n",
    "                event = child.attrib['event_type'].split(\"_\", 1)\n",
    "                events.append(event[1])\n",
    "            except KeyError:\n",
    "                events.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Name\" : names,\n",
    "                           \"Date\" : dates,\n",
    "                           \"Direction\": incident_dirs,\n",
    "                           \"Road\" : roads,\n",
    "                           \"Location\" : locations,\n",
    "                           \"Event\" : events})\n",
    "\n",
    "        print(DF)\n",
    "\n",
    "        print(\"Incident Data Parsed\")\n",
    "\n",
    "        with open('crash_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse detector information and save into csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "\n",
    "\n",
    "def detectors():\n",
    "        \n",
    "        sensors = []\n",
    "        times = []\n",
    "        flows = []\n",
    "        occupancies = []\n",
    "        speeds = []\n",
    "        XMLfile = \"det_sample.xml\"\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                sensors.append(child.attrib['sensor'])\n",
    "            except KeyError:\n",
    "                sensors.append(\"NA\")\n",
    "            try:\n",
    "                times.append(str(root.attrib['time_stamp']))\n",
    "            except KeyError:\n",
    "                times.append(\"NA\")\n",
    "            try:\n",
    "                flows.append(child.attrib['sample flow'])\n",
    "            except KeyError:\n",
    "                flows.append(\"NA\")\n",
    "            try:\n",
    "                occupancies.append(child.attrib['occ'])\n",
    "            except KeyError:\n",
    "                occupancies.append('NA')\n",
    "            try:\n",
    "                speeds.append(child.attrib['speed'])\n",
    "            except KeyError:\n",
    "                speeds.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Sensor\" : sensors,\n",
    "                            \"Time\" : times,\n",
    "                           \"Occupancy\": occupancies,\n",
    "                           \"Speed\" : speeds,\n",
    "                           \"Flow\" : flows})\n",
    "\n",
    "        print(DF)\n",
    "        print(\"Detector Data Parsed\")\n",
    "\n",
    "        with open('detector_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse station information and save as csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "\n",
    "\n",
    "\n",
    "def stations():\n",
    "        XMLfile = \"stat_config.xml\"\n",
    "\n",
    "        decription = []\n",
    "        times = []\n",
    "        detectors = []\n",
    "        lats = []\n",
    "        lngs = []\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "#         print(root.findall(\"./time_stamp\"))\n",
    "        for child in root:\n",
    "            try:\n",
    "                decription.append(child.attrib['description'])\n",
    "            except KeyError:\n",
    "                decription.append(\"NA\")\n",
    "            try:\n",
    "                times.append(str(root.attrib['tms_config_time_stamp']))\n",
    "            except KeyError:\n",
    "                times.append(\"NA\")\n",
    "            try:\n",
    "                detectors.append(child.attrib['name'])\n",
    "            except KeyError:\n",
    "                detectors.append(\"NA\")\n",
    "            try:\n",
    "                lats.append(child.attrib['lat'])\n",
    "            except KeyError:\n",
    "                lats.append('NA')\n",
    "            try:\n",
    "                lngs.append(child.attrib['lon'])\n",
    "            except KeyError:\n",
    "                lngs.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Label\" : decription,\n",
    "                           \"Sensor\" : detectors,\n",
    "                           \"Time\" : times,\n",
    "                           \"Lat\": lats,\n",
    "                           \"Lng\" : lngs})\n",
    "        \n",
    "        DF = DF.dropna(thresh=2)\n",
    "        print(DF)\n",
    "\n",
    "\n",
    "        with open('stat_config.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Label     Sensor Time       Lat        Lng\n",
      "0                               NA         NA   NA        NA         NA\n",
      "1                               NA         NA   NA        NA         NA\n",
      "2                               NA         NA   NA        NA         NA\n",
      "3                               NA         NA   NA        NA         NA\n",
      "4                               NA         NA   NA        NA         NA\n",
      "5                               NA         NA   NA        NA         NA\n",
      "6                               NA         NA   NA        NA         NA\n",
      "7                               NA         NA   NA        NA         NA\n",
      "8                               NA         NA   NA        NA         NA\n",
      "9                               NA         NA   NA        NA         NA\n",
      "10                              NA         NA   NA        NA         NA\n",
      "11                              NA         NA   NA        NA         NA\n",
      "12                              NA         NA   NA        NA         NA\n",
      "13                              NA         NA   NA        NA         NA\n",
      "14                              NA         NA   NA        NA         NA\n",
      "15                              NA         NA   NA        NA         NA\n",
      "16                              NA         NA   NA        NA         NA\n",
      "17                              NA         NA   NA        NA         NA\n",
      "18                              NA         NA   NA        NA         NA\n",
      "19                              NA         NA   NA        NA         NA\n",
      "20                              NA         NA   NA        NA         NA\n",
      "21                              NA         NA   NA        NA         NA\n",
      "22                              NA         NA   NA        NA         NA\n",
      "23                              NA         NA   NA        NA         NA\n",
      "24                              NA         NA   NA        NA         NA\n",
      "25                              NA         NA   NA        NA         NA\n",
      "26                              NA         NA   NA        NA         NA\n",
      "27                              NA         NA   NA        NA         NA\n",
      "28                              NA         NA   NA        NA         NA\n",
      "29                              NA         NA   NA        NA         NA\n",
      "...                            ...        ...  ...       ...        ...\n",
      "7640              I-94 EB @ 8th St    VT94E18   NA   45.6269  -94.57664\n",
      "7641            I-35 SB (MP 35.79)     V35S90   NA   43.9993   -93.2552\n",
      "7642             I-94 WB @ 1st Ave   L94W50_4   NA  44.96644  -93.27713\n",
      "7643            I-35 SB (MP 21.58)     V35S95   NA   43.8005   -93.2982\n",
      "7644     T.H.62 WB @ Lexington Ave    V110W01   NA  44.88388  -93.15014\n",
      "7645        I-35W SB N of Cliff Rd  L35WS75_1   NA  44.79008  -93.28906\n",
      "7646        I-35W SB N of Cliff Rd  L35WS75_2   NA  44.79008  -93.28902\n",
      "7647          T.H.62 EB @ Penn Ave     V62E02   NA        NA         NA\n",
      "7648        I-35W SB N of Cliff Rd  L35WS75_3   NA  44.79008  -93.28897\n",
      "7649             I-94 WB @ 1st Ave   L94W50_3   NA  44.96648  -93.27713\n",
      "7650        I-35W SB N of Cliff Rd  L35WS75_4   NA  44.79008  -93.28893\n",
      "7651             I-94 WB @ 1st Ave   L94W50_2   NA  44.96651  -93.27713\n",
      "7652     T.H.62 EB E of Gleason Rd     V62E01   NA  44.88844  -93.37838\n",
      "7653             I-94 WB @ 1st Ave   L94W50_1   NA  44.96685  -93.27507\n",
      "7654          T.H.62 EB @ Penn Ave     V62E03   NA  44.89063  -93.30888\n",
      "7655   T.H.62 EB E of Portland Ave     V62E05   NA  44.89042  -93.26013\n",
      "7656            I-35W SB @ 37th St  L35WS52_4   NA  44.93597  -93.27482\n",
      "7657            I-35W SB @ 37th St  L35WS52_3   NA  44.93597  -93.27486\n",
      "7658            I-35W SB @ 37th St  L35WS52_2   NA  44.93597  -93.27491\n",
      "7659            I-35W SB @ 37th St  L35WS52_1   NA  44.93597  -93.27495\n",
      "7660        I-35E SB @ Deerwood Dr    V35ES10   NA  44.81302  -93.18086\n",
      "7661            I-35 SB (MP 46.92)     V35S85   NA   44.1571   -93.2577\n",
      "7662         I-94 WB @ Sauk Centre    VT94W40   NA   45.7117   -94.9249\n",
      "7663  I-94 EB W of Tunnel Entrance   L94E50_2   NA   44.9729  -93.28758\n",
      "7664            I-35W NB @ 70th St  L35WN38_3   NA  44.87623  -93.29829\n",
      "7665            I-35W NB @ 70th St  L35WN38_2   NA  44.87623  -93.29825\n",
      "7666     T.H.100 SB @ Glenwood Ave   V100S01T   NA        NA         NA\n",
      "7667            I-35W NB @ 70th St  L35WN38_1   NA  44.87623   -93.2982\n",
      "7668  I-94 EB W of Tunnel Entrance   L94E50_1   NA   44.9729  -93.28763\n",
      "7669            I-35 SB (MP 62.24)     V35S80   NA   44.3612   -93.2932\n",
      "\n",
      "[7670 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Identify metro sensor configurations\n",
    "############################################\n",
    "# Request xml.gz file, decompress, decode\n",
    "# with the stat_config.xml, look for a matching station. If not found, write the new station ID to stat_config.csv\n",
    "\n",
    "s = requests.get('http://data.dot.state.mn.us/iris_xml/metro_config.xml.gz')\n",
    "with open('stat_config.xml', 'w') as handle:\n",
    "    handle.write(gzip.decompress(s.content).decode('utf-8'))\n",
    "\n",
    "XMLfile = \"stat_config.xml\"\n",
    "try:\n",
    "    with open('stat_config.csv', 'r') as CD:\n",
    "        stations()\n",
    "except FileNotFoundError:\n",
    "        Station_Data = pd.DataFrame(columns=['Label', 'Time', 'Detectors', 'Lat', 'Lng'])\n",
    "        with open('stat_config.csv', 'w') as f:\n",
    "            Station_Data.to_csv(f, header=True)\n",
    "            stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-9d7019c5e414>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-9d7019c5e414>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    download()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#If the program is still running, \n",
    "# Print the download is complete\n",
    "# Print the Parsing is Complete\n",
    "# Program sleep for 30 seconds\n",
    "####################################\n",
    "\n",
    "while True:\n",
    "    download()\n",
    "    print(\"download complete\")\n",
    "    data_check()\n",
    "    print(\"Parsing Complete, sleeping 30s\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 10, 3, 10, 13, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "# Adjust and parse time format\n",
    "##################################\n",
    "\n",
    "def time_xml2dt(time_xml):\n",
    "    from time import mktime\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    #time_xml='Wed Oct 03 10:13:27 CDT 2018'\n",
    "    B=time_xml.split()\n",
    "    B.pop(4)\n",
    "    B[4]=B[4][2:]\n",
    "    B_struct=time.strptime(' '.join(B), \"%a %b %d  %H:%M:%S %y\")\n",
    "    time_dt=datetime.fromtimestamp(mktime(B_struct))\n",
    "    return time_dt\n",
    "time_xml='Wed Oct 03 10:13:27 CDT 2018'\n",
    "time_xml2dt(time_xml)\n",
    "\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
