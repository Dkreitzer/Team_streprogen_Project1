{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "#Dependencies#\n",
    "##############\n",
    "\n",
    "import pandas as pd                              ### import pandas ###\n",
    "import os                                        ### import operating system ###\n",
    "import xml.etree.ElementTree as ET               ### xml.etree is a flexible container object,\n",
    "                                                 #   designed to store hierarchical data structures in memory.###\n",
    "import gzip                                      ### compress and decompress gzip files ###\n",
    "import time                                      ### import time libraries ###\n",
    "import shutil                                    ### Higher level copying and archiving ###\n",
    "import requests                                  ### Libraries to support HTML requests in python ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Defenition to pull Incident Reports and Traffic Detectors from MN DOT\n",
    "####################################################################\n",
    "# Request incident information - xml.gz file\n",
    "# Open, decompress, and decode\n",
    "# Request traffic detector information - xml.gz file\n",
    "# Open, decompress, and decode\n",
    "\n",
    "def download():\n",
    "    i = requests.get('http://data.dot.state.mn.us/iris_xml/incident.xml.gz')\n",
    "    with open('data/XMLs/incidents.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(i.content).decode('utf-8'))\n",
    "    d = requests.get('http://data.dot.state.mn.us/iris_xml/det_sample.xml.gz')\n",
    "    with open('data/XMLs/det_sample.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(d.content).decode('ISO-8859-1'))\n",
    "    s = requests.get('http://data.dot.state.mn.us/iris_xml/stat_sample.xml.gz')\n",
    "    with open('data/XMLs/station_sample.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(s.content).decode('ISO-8859-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Defenition to convert information in DataFrames\n",
    "###################################################\n",
    "# Identify crash information, try to open csv file and convert to DF, save updated DF as csv\n",
    "# Identify detector information, try to open as csv and convert to DF, save updated DF as csv\n",
    "\n",
    "\n",
    "\n",
    "def data_check():\n",
    "\n",
    "        try:\n",
    "            with open('data/crash_data.csv', 'r') as CD:\n",
    "                incidents()\n",
    "        except FileNotFoundError:\n",
    "                All_Crash_Data = pd.DataFrame(columns=['Name', 'Date', 'DirectionLocation', 'Road', '', 'Event'])\n",
    "                with open('data/crash_data.csv', 'w') as f:\n",
    "                    All_Crash_Data.to_csv(f, header=True)\n",
    "                    incidents()\n",
    "        try:\n",
    "            with open('data/detector_data.csv', 'r') as CD:\n",
    "                detectors()\n",
    "        except FileNotFoundError:\n",
    "                Detector_Data = pd.DataFrame(columns=['Sensor', 'Time', 'Occupancy', 'Speed', 'Flow'])\n",
    "                with open('data/detector_data.csv', 'w') as f:\n",
    "                    Detector_Data.to_csv(f, header=True)\n",
    "                    detectors()\n",
    "        try:\n",
    "            with open('data/station_data.csv', 'r') as CD:\n",
    "                stations()\n",
    "        except FileNotFoundError:\n",
    "                station_data = pd.DataFrame(columns=['Station', 'Time', 'Occupancy', 'Speed', 'Flow'])\n",
    "                with open('data/station_data.csv', 'w') as f:\n",
    "                    station_data.to_csv(f, header=True)\n",
    "                    stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse incident information and save into csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "\n",
    "def incidents():\n",
    "    dates = []\n",
    "    incident_dirs = []\n",
    "    roads = []\n",
    "    locations = []\n",
    "    names = []\n",
    "    events = []\n",
    "\n",
    "    XMLfile = \"data/XMLs/incidents.xml\"\n",
    "    parsedXML = ET.parse(XMLfile)\n",
    "    root = parsedXML.getroot()\n",
    "    for child in root:\n",
    "        try:\n",
    "            dates.append(child.attrib['event_date'])\n",
    "        except KeyError:\n",
    "            dates.append(\"NA\")\n",
    "        try:\n",
    "            names.append(str(child.attrib['name']))\n",
    "        except KeyError:\n",
    "            name.append(\"NA\")\n",
    "        try:\n",
    "            incident_dirs.append(child.attrib['dir'])\n",
    "        except KeyError:\n",
    "            incident_dir.append(\"NA\")\n",
    "        try:\n",
    "            roads.append(child.attrib['road'])\n",
    "        except KeyError:\n",
    "            roads.append('NA')\n",
    "        try:\n",
    "            locations.append(child.attrib['location'])\n",
    "        except KeyError:\n",
    "            locations.append(\"NA\")\n",
    "        try: \n",
    "            event = child.attrib['event_type'].split(\"_\", 1)\n",
    "            events.append(event[1])\n",
    "        except KeyError:\n",
    "            events.append(\"NA\")\n",
    "\n",
    "\n",
    "    DF = pd.DataFrame({\"Name\" : names,\n",
    "                       \"Date\" : dates,\n",
    "                       \"Direction\": incident_dirs,\n",
    "                       \"Road\" : roads,\n",
    "                       \"Location\" : locations,\n",
    "                       \"Event\" : events})\n",
    "\n",
    "\n",
    "    print(\"Incident Data Parsed\")\n",
    "\n",
    "    with open('data/crash_data.csv', 'a') as f:\n",
    "        DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse detector information and save into csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "\n",
    "def detectors():\n",
    "        \n",
    "        sensors = []\n",
    "        times = []\n",
    "        flows = []\n",
    "        occupancies = []\n",
    "        speeds = []\n",
    "        \n",
    "        XMLfile = \"data/XMLs/det_sample.xml\"\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                sensors.append(child.attrib['sensor'])\n",
    "            except KeyError:\n",
    "                sensors.append(\"NA\")\n",
    "            try:\n",
    "                times.append(str(root.attrib['time_stamp']))\n",
    "            except KeyError:\n",
    "                times.append(\"NA\")\n",
    "            try:\n",
    "                flows.append(child.attrib['flow'])\n",
    "            except KeyError:\n",
    "                flows.append(\"NA\")\n",
    "            try:\n",
    "                occupancies.append(child.attrib['occ'])\n",
    "            except KeyError:\n",
    "                occupancies.append('NA')\n",
    "            try:\n",
    "                speeds.append(child.attrib['speed'])\n",
    "            except KeyError:\n",
    "                speeds.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Sensor\" : sensors,\n",
    "                            \"Time\" : times,\n",
    "                           \"Occupancy\": occupancies,\n",
    "                           \"Speed\" : speeds,\n",
    "                           \"Flow\" : flows})\n",
    "\n",
    "        print(\"Detector Data Parsed\")\n",
    "\n",
    "        with open('data/detector_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Parse station information and save as csv\n",
    "###################################################\n",
    "\n",
    "## Create lists, append lists if data exists otherwise enter NA, combine data as DF, save as csv\n",
    "def stations():\n",
    "    stations = []\n",
    "    times = []\n",
    "    flows = []\n",
    "    occupancies = []\n",
    "    speeds = []\n",
    "\n",
    "    XMLfile = \"data/XMLs/station_sample.xml\"\n",
    "    parsedXML = ET.parse(XMLfile)\n",
    "    root = parsedXML.getroot()\n",
    "    for child in root:\n",
    "        try:\n",
    "            stations.append(child.attrib['sensor'])\n",
    "        except KeyError:\n",
    "            stations.append(\"NA\")\n",
    "        try:\n",
    "            times.append(str(root.attrib['time_stamp']))\n",
    "        except KeyError:\n",
    "            times.append(\"NA\")\n",
    "        try:\n",
    "            flows.append(child.attrib['flow'])\n",
    "        except KeyError:\n",
    "            flows.append(\"NA\")\n",
    "        try:\n",
    "            occupancies.append(child.attrib['occ'])\n",
    "        except KeyError:\n",
    "            occupancies.append('NA')\n",
    "        try:\n",
    "            speeds.append(child.attrib['speed'])\n",
    "        except KeyError:\n",
    "            speeds.append(\"NA\")\n",
    "\n",
    "\n",
    "    DF = pd.DataFrame({\"Station\" : stations,\n",
    "                        \"Time\" : times,\n",
    "                       \"Occupancy\": occupancies,\n",
    "                       \"Speed\" : speeds,\n",
    "                       \"Flow\" : flows})\n",
    "\n",
    "    print(\"Station Data Parsed\")\n",
    "\n",
    "    with open('data/station_data.csv', 'a') as f:\n",
    "        DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 10, 3, 10, 13, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "# Adjust and parse time format\n",
    "##################################\n",
    "\n",
    "def time_xml2dt(time_xml):\n",
    "    from time import mktime\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    #time_xml='Wed Oct 03 10:13:27 CDT 2018'\n",
    "    B=time_xml.split()\n",
    "    B.pop(4)\n",
    "    B[4]=B[4][2:]\n",
    "    B_struct=time.strptime(' '.join(B), \"%a %b %d  %H:%M:%S %y\")\n",
    "    time_dt=datetime.fromtimestamp(mktime(B_struct))\n",
    "    return time_dt\n",
    "time_xml='Wed Oct 03 10:13:27 CDT 2018'\n",
    "time_xml2dt(time_xml)\n",
    "\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "#     decription = []\n",
    "    lats = []\n",
    "    lngs = []\n",
    "    station_list = []\n",
    "        \n",
    "    XMLfile = \"data/XMLs/station_config.xml\"\n",
    "    parsedXML = ET.parse(XMLfile)\n",
    "    root = parsedXML.getroot()\n",
    "      \n",
    "\n",
    "    for i in root.iter('corridor'):\n",
    "        for child in i:\n",
    "            try:\n",
    "                station_list.append(child.attrib['station_id'])\n",
    "\n",
    "            except KeyError:\n",
    "                station_list.append(\"no ID\")\n",
    "            try:\n",
    "                lats.append(child.attrib['lat'])\n",
    "            except KeyError:\n",
    "                 lats.append(\"no ID\")\n",
    "            try:\n",
    "                lngs.append(child.attrib['lon'])\n",
    "            except KeyError:\n",
    "                lngs.append(\"no ID\")\n",
    "\n",
    "#             try:\n",
    "#                 decription.append(child.attrib['description'])\n",
    "#             except KeyError:\n",
    "#                 decription.append(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "    DF = pd.DataFrame({ \"Station\":station_list,\n",
    "    #                        \"Label\":decription,\n",
    "                       \"Lat\":lats, \"Lng\":lngs,})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open('data/station_config.csv', 'a') as f:\n",
    "        DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Identify metro sensor configurations\n",
    "############################################\n",
    "# Request xml.gz file, decompress, decode\n",
    "# with the stat_config.xml, look for a matching station. If not found, write the new station ID to stat_config.csv\n",
    "\n",
    "c = requests.get('http://data.dot.state.mn.us/iris_xml/metro_config.xml.gz')\n",
    "with open('data/XMLs/station_config.xml', 'w') as handle:\n",
    "    handle.write(gzip.decompress(c.content).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Route_Summary():\n",
    "    Route = ['S567','S583','S568','S582','S569','S570','S581','S580','S571','S579','S572','S578','S573',\"S577\",\"S587\"]\n",
    "    try:\n",
    "        with open('data/station_config.csv', 'r') as CD:\n",
    "            config()\n",
    "    except FileNotFoundError:\n",
    "            Station_Config = pd.DataFrame(columns=['Station', 'Lat', 'Lng'])\n",
    "            with open('data/station_config.csv', 'w') as f:\n",
    "                Station_Config.to_csv(f, header=True)\n",
    "                config()\n",
    "\n",
    "    Station_Config = pd.read_csv('data/station_config.csv')\n",
    "    Station_Config = Station_Config.set_index('Station')\n",
    "\n",
    "    All_Station_Data = pd.read_csv('data/station_data.csv')\n",
    "    All_Station_Data = All_Station_Data[[\"Station\", \"Time\", \"Occupancy\", \"Speed\", \"Flow\"]]\n",
    "    All_Station_Data = All_Station_Data.set_index('Station')\n",
    "    \n",
    "    Route_Summary = []\n",
    "    for station in Route:\n",
    "#             Route_Summary.append(Station_Config.loc[station, ['Lat', 'Lng']])\n",
    "# we can grab it here, but repeats. better to grab as needed when graphing\n",
    "            Route_Summary.append(All_Station_Data.loc[station, \n",
    "                                                       ['Time', 'Occupancy', 'Speed', 'Flow']])\n",
    "            \n",
    "                \n",
    "            \n",
    "    # for Summary in Route_Summary:\n",
    "        ## WHAT ARE WE DOING WITH THESE?##\n",
    "    print(Route_Summary[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident Data Parsed\n",
      "Detector Data Parsed\n",
      "Station Data Parsed\n",
      "                                 Time Occupancy Speed  Flow\n",
      "Station                                                    \n",
      "S567     Thu Oct 04 21:19:59 CDT 2018      5.54    61   760\n",
      "S567     Fri Oct 05 06:36:29 CDT 2018       9.7    54  1120\n",
      "S567     Fri Oct 05 06:36:59 CDT 2018      7.67    49   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:59 CDT 2018      9.06    63  1280\n",
      "S567     Fri Oct 05 06:39:59 CDT 2018       6.5    50   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:45:29 CDT 2018     10.74    56  1320\n",
      "S567     Fri Oct 05 06:45:59 CDT 2018       8.5    54  1040\n",
      "S567     Fri Oct 05 06:46:29 CDT 2018      8.59    53  1040\n",
      "S567     Fri Oct 05 06:46:59 CDT 2018      9.39    57  1200\n",
      "S567     Fri Oct 05 06:47:29 CDT 2018      7.11    58   920\n",
      "S567     Fri Oct 05 06:47:59 CDT 2018      7.63    54   920\n",
      "S567     Fri Oct 05 07:05:59 CDT 2018     10.13    63  1400\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:41:29 CDT 2018      9.67    58  1240\n",
      "S567     Fri Oct 05 09:41:59 CDT 2018      8.59    61  1200\n",
      "S567     Fri Oct 05 09:44:29 CDT 2018     10.28    52  1200\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:13:59 CDT 2018      6.85    51   760\n",
      "S567     Fri Oct 05 10:15:59 CDT 2018       9.8    54  1200\n",
      "S567     Fri Oct 05 10:16:29 CDT 2018      7.63    60  1000\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:59 CDT 2018     10.24    54  1240\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:59 CDT 2018      6.65    51   760\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:39:29 CDT 2018      9.13    59  1240\n",
      "S567     Fri Oct 05 10:39:59 CDT 2018       6.7    60   920\n",
      "S567     Fri Oct 05 10:41:59 CDT 2018      5.67    61   760\n",
      "S567     Fri Oct 05 10:42:59 CDT 2018      8.48    57  1080\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:45:29 CDT 2018      9.59    63  1360\n",
      "S567     Fri Oct 05 10:45:59 CDT 2018      7.28    57   920\n",
      "S567     Fri Oct 05 10:48:29 CDT 2018       8.5    55  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n"
     ]
    }
   ],
   "source": [
    "download()\n",
    "data_check()\n",
    "Route_Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download complete\n",
      "Incident Data Parsed\n",
      "Detector Data Parsed\n",
      "Station Data Parsed\n",
      "Parsing Complete, sleeping 30s\n",
      "                                 Time Occupancy Speed  Flow\n",
      "Station                                                    \n",
      "S567     Thu Oct 04 21:19:59 CDT 2018      5.54    61   760\n",
      "S567     Fri Oct 05 06:36:29 CDT 2018       9.7    54  1120\n",
      "S567     Fri Oct 05 06:36:59 CDT 2018      7.67    49   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:59 CDT 2018      9.06    63  1280\n",
      "S567     Fri Oct 05 06:39:59 CDT 2018       6.5    50   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:45:29 CDT 2018     10.74    56  1320\n",
      "S567     Fri Oct 05 06:45:59 CDT 2018       8.5    54  1040\n",
      "S567     Fri Oct 05 06:46:29 CDT 2018      8.59    53  1040\n",
      "S567     Fri Oct 05 06:46:59 CDT 2018      9.39    57  1200\n",
      "S567     Fri Oct 05 06:47:29 CDT 2018      7.11    58   920\n",
      "S567     Fri Oct 05 06:47:59 CDT 2018      7.63    54   920\n",
      "S567     Fri Oct 05 07:05:59 CDT 2018     10.13    63  1400\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:41:29 CDT 2018      9.67    58  1240\n",
      "S567     Fri Oct 05 09:41:59 CDT 2018      8.59    61  1200\n",
      "S567     Fri Oct 05 09:44:29 CDT 2018     10.28    52  1200\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:13:59 CDT 2018      6.85    51   760\n",
      "S567     Fri Oct 05 10:15:59 CDT 2018       9.8    54  1200\n",
      "S567     Fri Oct 05 10:16:29 CDT 2018      7.63    60  1000\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:59 CDT 2018     10.24    54  1240\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:59 CDT 2018      6.65    51   760\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:39:29 CDT 2018      9.13    59  1240\n",
      "S567     Fri Oct 05 10:39:59 CDT 2018       6.7    60   920\n",
      "S567     Fri Oct 05 10:41:59 CDT 2018      5.67    61   760\n",
      "S567     Fri Oct 05 10:42:59 CDT 2018      8.48    57  1080\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:45:29 CDT 2018      9.59    63  1360\n",
      "S567     Fri Oct 05 10:45:59 CDT 2018      7.28    57   920\n",
      "S567     Fri Oct 05 10:48:29 CDT 2018       8.5    55  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "download complete\n",
      "Incident Data Parsed\n",
      "Detector Data Parsed\n",
      "Station Data Parsed\n",
      "Parsing Complete, sleeping 30s\n",
      "                                 Time Occupancy Speed  Flow\n",
      "Station                                                    \n",
      "S567     Thu Oct 04 21:19:59 CDT 2018      5.54    61   760\n",
      "S567     Fri Oct 05 06:36:29 CDT 2018       9.7    54  1120\n",
      "S567     Fri Oct 05 06:36:59 CDT 2018      7.67    49   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:59 CDT 2018      9.06    63  1280\n",
      "S567     Fri Oct 05 06:39:59 CDT 2018       6.5    50   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:45:29 CDT 2018     10.74    56  1320\n",
      "S567     Fri Oct 05 06:45:59 CDT 2018       8.5    54  1040\n",
      "S567     Fri Oct 05 06:46:29 CDT 2018      8.59    53  1040\n",
      "S567     Fri Oct 05 06:46:59 CDT 2018      9.39    57  1200\n",
      "S567     Fri Oct 05 06:47:29 CDT 2018      7.11    58   920\n",
      "S567     Fri Oct 05 06:47:59 CDT 2018      7.63    54   920\n",
      "S567     Fri Oct 05 07:05:59 CDT 2018     10.13    63  1400\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:41:29 CDT 2018      9.67    58  1240\n",
      "S567     Fri Oct 05 09:41:59 CDT 2018      8.59    61  1200\n",
      "S567     Fri Oct 05 09:44:29 CDT 2018     10.28    52  1200\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:13:59 CDT 2018      6.85    51   760\n",
      "S567     Fri Oct 05 10:15:59 CDT 2018       9.8    54  1200\n",
      "S567     Fri Oct 05 10:16:29 CDT 2018      7.63    60  1000\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:59 CDT 2018     10.24    54  1240\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:59 CDT 2018      6.65    51   760\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:39:29 CDT 2018      9.13    59  1240\n",
      "S567     Fri Oct 05 10:39:59 CDT 2018       6.7    60   920\n",
      "S567     Fri Oct 05 10:41:59 CDT 2018      5.67    61   760\n",
      "S567     Fri Oct 05 10:42:59 CDT 2018      8.48    57  1080\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:45:29 CDT 2018      9.59    63  1360\n",
      "S567     Fri Oct 05 10:45:59 CDT 2018      7.28    57   920\n",
      "S567     Fri Oct 05 10:48:29 CDT 2018       8.5    55  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "S567     Fri Oct 05 10:49:29 CDT 2018      6.91    63  1000\n",
      "download complete\n",
      "Incident Data Parsed\n",
      "Detector Data Parsed\n",
      "Station Data Parsed\n",
      "Parsing Complete, sleeping 30s\n",
      "                                 Time Occupancy Speed  Flow\n",
      "Station                                                    \n",
      "S567     Thu Oct 04 21:19:59 CDT 2018      5.54    61   760\n",
      "S567     Fri Oct 05 06:36:29 CDT 2018       9.7    54  1120\n",
      "S567     Fri Oct 05 06:36:59 CDT 2018      7.67    49   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:29 CDT 2018      7.06    58   840\n",
      "S567     Fri Oct 05 06:37:59 CDT 2018      9.06    63  1280\n",
      "S567     Fri Oct 05 06:39:59 CDT 2018       6.5    50   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:44:59 CDT 2018      6.31    52   720\n",
      "S567     Fri Oct 05 06:45:29 CDT 2018     10.74    56  1320\n",
      "S567     Fri Oct 05 06:45:59 CDT 2018       8.5    54  1040\n",
      "S567     Fri Oct 05 06:46:29 CDT 2018      8.59    53  1040\n",
      "S567     Fri Oct 05 06:46:59 CDT 2018      9.39    57  1200\n",
      "S567     Fri Oct 05 06:47:29 CDT 2018      7.11    58   920\n",
      "S567     Fri Oct 05 06:47:59 CDT 2018      7.63    54   920\n",
      "S567     Fri Oct 05 07:05:59 CDT 2018     10.13    63  1400\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:40:59 CDT 2018      7.41    60  1000\n",
      "S567     Fri Oct 05 09:41:29 CDT 2018      9.67    58  1240\n",
      "S567     Fri Oct 05 09:41:59 CDT 2018      8.59    61  1200\n",
      "S567     Fri Oct 05 09:44:29 CDT 2018     10.28    52  1200\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:08:29 CDT 2018      5.65    68   880\n",
      "S567     Fri Oct 05 10:13:59 CDT 2018      6.85    51   760\n",
      "S567     Fri Oct 05 10:15:59 CDT 2018       9.8    54  1200\n",
      "S567     Fri Oct 05 10:16:29 CDT 2018      7.63    60  1000\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:29 CDT 2018      4.76    73   760\n",
      "S567     Fri Oct 05 10:17:59 CDT 2018     10.24    54  1240\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:29 CDT 2018      5.57    59   760\n",
      "S567     Fri Oct 05 10:18:59 CDT 2018      6.65    51   760\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:21:29 CDT 2018      9.13    52  1080\n",
      "S567     Fri Oct 05 10:39:29 CDT 2018      9.13    59  1240\n",
      "S567     Fri Oct 05 10:39:59 CDT 2018       6.7    60   920\n",
      "S567     Fri Oct 05 10:41:59 CDT 2018      5.67    61   760\n",
      "S567     Fri Oct 05 10:42:59 CDT 2018      8.48    57  1080\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:43:59 CDT 2018       7.3    59   960\n",
      "S567     Fri Oct 05 10:45:29 CDT 2018      9.59    63  1360\n",
      "S567     Fri Oct 05 10:45:59 CDT 2018      7.28    57   920\n",
      "S567     Fri Oct 05 10:48:29 CDT 2018       8.5    55  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "S567     Fri Oct 05 10:48:59 CDT 2018      7.57    60  1000\n",
      "S567     Fri Oct 05 10:49:29 CDT 2018      6.91    63  1000\n",
      "S567     Fri Oct 05 10:49:59 CDT 2018      6.87    57   800\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#If the program is still running, \n",
    "# Print the download is complete\n",
    "# Print the Parsing is Complete\n",
    "# Program sleep for 30 seconds\n",
    "# ####################################\n",
    "\n",
    "while True:\n",
    "    download()\n",
    "    print(\"download complete\")\n",
    "    data_check()\n",
    "    print(\"Parsing Complete, sleeping 30s\")\n",
    "    Route_Summary()\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
