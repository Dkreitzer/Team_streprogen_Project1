{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import time\n",
    "import shutil\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    i = requests.get('http://data.dot.state.mn.us/iris_xml/incident.xml.gz')\n",
    "    with open('data/XMLs/incidents.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(i.content).decode('utf-8'))\n",
    "    d = requests.get('http://data.dot.state.mn.us/iris_xml/det_sample.xml.gz')\n",
    "    with open('data/XMLs/det_sample.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(d.content).decode('ISO-8859-1'))\n",
    "    s = requests.get('http://data.dot.state.mn.us/iris_xml/stat_sample.xml.gz')\n",
    "    with open('data/XMLs/stat_sample.xml', 'w') as handle:\n",
    "        handle.write(gzip.decompress(s.content).decode('ISO-8859-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_check():\n",
    "\n",
    "\n",
    "        try:\n",
    "            with open('data/crash_data.csv', 'r') as CD:\n",
    "                incidents()\n",
    "        except FileNotFoundError:\n",
    "                All_Crash_Data = pd.DataFrame(columns=['Name', 'Date', 'DirectionLocation', 'Road', '', 'Event'])\n",
    "                with open('data/crash_data.csv', 'w') as f:\n",
    "                    All_Crash_Data.to_csv(f, header=True)\n",
    "                    incidents()\n",
    "        try:\n",
    "            with open('data/detector_data.csv', 'r') as CD:\n",
    "                detectors()\n",
    "        except FileNotFoundError:\n",
    "                Detector_Data = pd.DataFrame(columns=['Sensor', 'Time', 'Occupancy', 'Speed', 'Flow'])\n",
    "                with open('data/detector_data.csv', 'w') as f:\n",
    "                    Detector_Data.to_csv(f, header=True)\n",
    "                    detectors()\n",
    "        try:\n",
    "            with open('data/station_data.csv', 'r') as CD:\n",
    "                stations()\n",
    "        except FileNotFoundError:\n",
    "                station_data = pd.DataFrame(columns=['Station', 'Time', 'Occupancy', 'Speed', 'Flow'])\n",
    "                with open('data/station_data.csv', 'w') as f:\n",
    "                    station_data.to_csv(f, header=True)\n",
    "                    stations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stations():\n",
    "        \n",
    "        stations = []\n",
    "        times = []\n",
    "        flows = []\n",
    "        occupancies = []\n",
    "        speeds = []\n",
    "        XMLfile = \"data/XMLs/stat_sample.xml\"\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                stations.append(child.attrib['sensor'])\n",
    "            except KeyError:\n",
    "                stations.append(\"NA\")\n",
    "            try:\n",
    "                times.append(str(root.attrib['time_stamp']))\n",
    "            except KeyError:\n",
    "                times.append(\"NA\")\n",
    "            try:\n",
    "                flows.append(child.attrib['sample flow'])\n",
    "            except KeyError:\n",
    "                flows.append(\"NA\")\n",
    "            try:\n",
    "                occupancies.append(child.attrib['occ'])\n",
    "            except KeyError:\n",
    "                occupancies.append('NA')\n",
    "            try:\n",
    "                speeds.append(child.attrib['speed'])\n",
    "            except KeyError:\n",
    "                speeds.append(\"NA\")\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Station\" : stations,\n",
    "                            \"Time\" : times,\n",
    "                           \"Occupancy\": occupancies,\n",
    "                           \"Speed\" : speeds,\n",
    "                           \"Flow\" : flows})\n",
    "\n",
    "        print(DF)\n",
    "        print(\"Station Data Parsed\")\n",
    "\n",
    "        with open('data/station_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidents():\n",
    "        XMLfile = \"data/XMLs/incidents.xml\"\n",
    "\n",
    "\n",
    "        dates = []\n",
    "        incident_dirs = []\n",
    "        roads = []\n",
    "        locations = []\n",
    "        names = []\n",
    "        events = []\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                dates.append(child.attrib['event_date'])\n",
    "            except KeyError:\n",
    "                dates.append(\"NA\")\n",
    "            try:\n",
    "                names.append(str(child.attrib['name']))\n",
    "            except KeyError:\n",
    "                name.append(\"NA\")\n",
    "            try:\n",
    "                incident_dirs.append(child.attrib['dir'])\n",
    "            except KeyError:\n",
    "                incident_dir.append(\"NA\")\n",
    "            try:\n",
    "                roads.append(child.attrib['road'])\n",
    "            except KeyError:\n",
    "                roads.append('NA')\n",
    "            try:\n",
    "                locations.append(child.attrib['location'])\n",
    "            except KeyError:\n",
    "                locations.append(\"NA\")\n",
    "            try: \n",
    "                event = child.attrib['event_type'].split(\"_\", 1)\n",
    "                events.append(event[1])\n",
    "            except KeyError:\n",
    "                events.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Name\" : names,\n",
    "                           \"Date\" : dates,\n",
    "                           \"Direction\": incident_dirs,\n",
    "                           \"Road\" : roads,\n",
    "                           \"Location\" : locations,\n",
    "                           \"Event\" : events})\n",
    "\n",
    "        print(DF)\n",
    "\n",
    "        print(\"Incident Data Parsed\")\n",
    "\n",
    "        with open('data/crash_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectors():\n",
    "        \n",
    "        sensors = []\n",
    "        times = []\n",
    "        flows = []\n",
    "        occupancies = []\n",
    "        speeds = []\n",
    "        XMLfile = \"data/XMLs/det_sample.xml\"\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                sensors.append(child.attrib['sensor'])\n",
    "            except KeyError:\n",
    "                sensors.append(\"NA\")\n",
    "            try:\n",
    "                times.append(str(root.attrib['time_stamp']))\n",
    "            except KeyError:\n",
    "                times.append(\"NA\")\n",
    "            try:\n",
    "                flows.append(child.attrib['sample flow'])\n",
    "            except KeyError:\n",
    "                flows.append(\"NA\")\n",
    "            try:\n",
    "                occupancies.append(child.attrib['occ'])\n",
    "            except KeyError:\n",
    "                occupancies.append('NA')\n",
    "            try:\n",
    "                speeds.append(child.attrib['speed'])\n",
    "            except KeyError:\n",
    "                speeds.append(\"NA\")\n",
    "\n",
    "\n",
    "\n",
    "        DF = pd.DataFrame({\"Sensor\" : sensors,\n",
    "                            \"Time\" : times,\n",
    "                           \"Occupancy\": occupancies,\n",
    "                           \"Speed\" : speeds,\n",
    "                           \"Flow\" : flows})\n",
    "\n",
    "        print(DF)\n",
    "        print(\"Detector Data Parsed\")\n",
    "\n",
    "        with open('data/detector_data.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "        XMLfile = \"data/XMLs/stat_config.xml\"\n",
    "\n",
    "        decription = []\n",
    "        station = []\n",
    "        lats = []\n",
    "        lngs = []\n",
    "\n",
    "        parsedXML = ET.parse(XMLfile)\n",
    "        root = parsedXML.getroot()\n",
    "        for child in root:\n",
    "            try:\n",
    "                lats.append(child.attrib['lat'])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            try:\n",
    "                lngs.append(child.attrib['lon'])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                decription.append(child.attrib['description'])\n",
    "            except KeyError:\n",
    "                    decription.append(\"error\")\n",
    "\n",
    "        \n",
    "            try:\n",
    "                station.append(child.attrib['name'])\n",
    "            except KeyError:\n",
    "                station.append(\"error\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                ### NODE NAMES ARE FOUND IN CHILD[0][X]#####\n",
    "            \n",
    "      \n",
    "        DF = pd.DataFrame({\"Label\" : decription,\n",
    "                           \"Sensor\" : station,\n",
    "                           \"Lat\": lats,\n",
    "                           \"Lng\" : lngs})\n",
    "        \n",
    "        DF = DF.dropna(thresh=2)\n",
    "        print(DF)\n",
    "\n",
    "\n",
    "        with open('data/stat_config.csv', 'a') as f:\n",
    "            DF.to_csv(f, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = requests.get('http://data.dot.state.mn.us/iris_xml/metro_config.xml.gz')\n",
    "with open('data/XMLs/stat_config.xml', 'w') as handle:\n",
    "    handle.write(gzip.decompress(c.content).decode('utf-8'))\n",
    "try:\n",
    "    with open('stat_config.csv', 'r') as CD:\n",
    "        config()\n",
    "except FileNotFoundError:\n",
    "        Station_Data = pd.DataFrame(columns=['Label', 'Detectors', 'Lat', 'Lng'])\n",
    "        with open('data/stat_config.csv', 'w') as f:\n",
    "            Station_Data.to_csv(f, header=True)\n",
    "            config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f883391a6fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAll_Station_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/station_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAll_Station_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAll_Station_Data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Station\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Occupancy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Speed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Flow\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mAll_Station_Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAll_Station_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Station'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Route_Name = input(\"  Name Your Route\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mRoute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m584\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m567\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m583\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m568\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m582\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m569\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m570\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m581\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m580\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m571\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m579\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m572\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m578\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m573\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m577\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m587\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "All_Station_Data = pd.read_csv('data/station_data.csv')\n",
    "All_Station_Data = All_Station_Data[[\"Station\", \"Time\", \"Occupancy\", \"Speed\", \"Flow\"]]\n",
    "All_Station_Data = All_Station_Data.set_index('Station')\n",
    "# Route_Name = input(\"  Name Your Route\")\n",
    "Route = [584,567,583,568,582,569,570,581,580,571,579,572,578,573,577,587]\n",
    "Route_Summary = []\n",
    "for station in Route:\n",
    "        Route_Summary.append(All_Station_Data.loc['S'+ str(station), ['Time', 'Occupancy', 'Speed', 'Flow']])\n",
    "# for Summary in Route_Summary:\n",
    "    ## WHAT ARE WE DOING WITH THESE?##\n",
    "Route_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    download()\n",
    "    print(\"download complete\")\n",
    "    data_check()\n",
    "    print(\"Parsing Complete, sleeping 30s\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
